# Modeling

## PART I: Creating the Prediction Machine Learning Models

### Step 1: Import Required Libraries

```python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
```

## Step 2: Load Your **Cleaned and Feature-Engineered Dataset**

_This dataset will come from after running the 'data_cleaning' script first_

> _Most datasets that you will be working with are going to be csv files. If you have an xls file instead, convert it to a csv file first._

- For importing from local files and especially when using 'example.py' files

`df = pd.read_csv('cleaned_and_feature_engineered_healthcare_dataset.csv')`

- For importing from local files but using a Notebook environment, like Jupyter, with files ending in 'example.ipynb'

`df = pd.read_csv('C:/Users/Caroline/Documents/GitHub/reop_name/Data/Raw_Data/cleaned_and_feature_engineered_healthcare_dataset.csv')`

## Step 3: Define Your Input Features and Target

```python
X = df.drop(columns='target')  # Replace 'target' with your target column name
y = df['target']  # Replace 'target' with your target column name

```

## Step 4: Split Your Data into Training and Testing Sets

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```

## Step 5: Train Your Model

Here we're using a RandomForestRegressor as an example, but you can substitute it with any appropriate model based on your problem.

## Step 6: Make Predictions and Evaluate Your Model

## Step 7: Hyperparameter Tuning

## Step 8: Inspect the Best Hyperparameters

## PART II: Deploying the Model for Future Predictions
