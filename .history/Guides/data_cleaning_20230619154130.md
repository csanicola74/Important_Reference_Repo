# Data Cleaning

_Cleaning a dataset (specifically for healthcare data) that is from the raw output. This method is assuming that no prior manipulation of the dataset has occured and it is a raw csv file being worked on._

## PART I: Understanding the Dataset

### Step 1: Importing the Libraries

First, you need to import the necessary libraries.

```python
%matplotlib inline

import warnings
# Load/Review/Visualize
from zipfile import ZipFile
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# for K-Mean
from sklearn.cluster import KMeans
from pandas.plotting import parallel_coordinates
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
# Model/Prediction
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier
import statsmodels.api as sm
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import statsmodels.api as sm
from statsmodels.tsa.statespace.sarimax import SARIMAX

import math

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

import json
import matplotlib
import datetime
from matplotlib import cm
import glob
import re
import os
import io
from scipy.stats import boxcox
```

### Step 2: Importing the dataset

Load your dataset using pandas. We assume that the dataset is in csv format.

> _Most datasets that you will be working with are going to be csv files. If you have an xls file instead, convert it to a csv file first._

- For importing from local files and especially when using 'example.py' files

`df = pd.read_csv('healthcare_dataset.csv')`

- For importing from local files but using a Notebook environment, like Jupyter, with files ending in 'example.ipynb'

`df = pd.read_csv('C:/Users/Caroline/Documents/GitHub/reop_name/Data/Raw_Data/healthcare_dataset.csv')`

### Step 3: Understanding the dataset

It's important to have a grasp on what your dataset looks like. Below commands will provide some insights.

```python
# This will print the first 5 rows of the dataframe
print(df.head())

# This will give information about the dataset like total values in each column, null count and data type
print(df.info())

# This will give the statistical summary of the dataset
print(df.describe())
```

### Step 4: Handling Missing Values

Missing values need to be handled carefully as they can lead to misleading results.

```python
# Check the number of missing values in each column
print(df.isnull().sum())

# If the missing values are not significant, you might choose to drop rows or columns.
# Drop rows with any column having NA/null data.
df = df.dropna()

# Alternatively, you might choose to fill missing values with mean, median or mode.
# Let's fill missing values with the mean
for col in df.columns:
    if df[col].dtype == 'float64' or df[col].dtype == 'int64':
        df[col] = df[col].fillna(df[col].mean())

```

### Step 5: Handing Duplicates

Duplicate rows can be present in the data. If they are not meaningful, they should be removed.

```python
# Drop duplicates
df = df.drop_duplicates()

```

### Step 6: Renaming Columns

Sometimes column names can be confusing or not meaningful, it's good practice to rename column names for clarity.

---

**TAGS**: #markdown #data_cleaning
